

<!DOCTYPE html>
<html lang="en">

<head>
  <script async src= "https://www.googletagmanager.com/gtag/js?id=G-E5TZ32BZDF "></script> <script>  window.dataLayer = window.dataLayer || [];  function gtag(){dataLayer.push(arguments);}  gtag('js', new Date());  gtag('config', 'G-E5TZ32BZDF'); </script>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AI Research Agent - Docs dataset-import/compile-topic-model.js</title>

  <script src="https://cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js"></script>
  <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  <script src="./build/entry.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link href="https://fonts.googleapis.com/css?family=Roboto:100,400,700|Inconsolata,700" rel="stylesheet">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
  <link type="text/css" rel="stylesheet" href="https://jmblog.github.io/color-themes-for-google-code-prettify/themes/tomorrow-night.min.css">
  <link type="text/css" rel="stylesheet" href="styles/app.min.css">
  <link type="text/css" rel="stylesheet" href="styles/iframe.css">
  <link type="text/css" rel="stylesheet" href="">
  <script async defer src="https://buttons.github.io/buttons.js"></script>

  
</head>



<body class="layout small-header">
    <div id="stickyNavbarOverlay"></div>
    

<div class="top-nav">
    <div class="inner">
        <a id="hamburger" role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
        <div class="logo">
            
             
                <a href="index.html">
                    <h1 class="navbar-item">AI Research Agent</h1>
                </a>
            
        </div>
        <div class="menu">
            
            <div class="navigation">
                <a
                    href="index.html"
                    class="link"
                >
                    Documentation
                </a>
                
                 
                    
                        <a
                            class="link user-link "
                            href="https://github.com/vtempest/ai-research-agent"
                        >
                            Source Code
                        </a>
                    
                        <a
                            class="link user-link "
                            href="https://qwksearch.com"
                        >
                            Live Demo
                        </a>
                    
                        <a
                            class="link user-link "
                            href="https://discord.gg/SJdBqBz3tV"
                        >
                            Discord Chat
                        </a>
                    
                
                
            </div>
        </div>
    </div>
</div>
    <div id="main">
        <div
            class="sidebar "
            id="sidebarNav"
        >
            
                <div class="search-wrapper">
                    <input id="search" type="text" placeholder="Search docs..." class="input">
                </div>
            
            <nav>
                
                    <h2><a href="index.html">Documentation</a></h2><div class="category"><h3>Global</h3><ul><li><a href="global.html#modifyChromeAPIAllowCORS">modifyChromeAPIAllowCORS</a></li></ul></div><div class="category"><h2>Extractor</h2><h3>Global</h3><ul><li><a href="global.html#convertHTMLSpecialChars">convertHTMLSpecialChars</a></li><li><a href="global.html#convertHTMLToBasicHTML">convertHTMLToBasicHTML</a></li><li><a href="global.html#convertURLToDomain">convertURLToDomain</a></li><li><a href="global.html#embedYoutubePlayer">embedYoutubePlayer</a></li><li><a href="global.html#extract">extract</a></li><li><a href="global.html#extractCite">extractCite</a></li><li><a href="global.html#extractFavicon">extractFavicon</a></li><li><a href="global.html#extractNamedEntity">extractNamedEntity</a></li><li><a href="global.html#extractNamedEntityParts">extractNamedEntityParts</a></li><li><a href="global.html#extractPDF">extractPDF</a></li><li><a href="global.html#extractYoutubeText">extractYoutubeText</a></li><li><a href="global.html#isHTMLBotDetection">isHTMLBotDetection</a></li><li><a href="global.html#isUrlPDF">isUrlPDF</a></li><li><a href="global.html#scrapeURL">scrapeURL</a></li></ul></div><div class="category"><h2>Relevance</h2><h3>Global</h3><ul><li><a href="global.html#calculateCosineSimilarity">calculateCosineSimilarity</a></li><li><a href="global.html#calculatePhraseSpecificity">calculatePhraseSpecificity</a></li><li><a href="global.html#calculateSimilarityByCharacter">calculateSimilarityByCharacter</a></li><li><a href="global.html#calculateSoftmax">calculateSoftmax</a></li><li><a href="global.html#matchQUASAR">matchQUASAR</a></li><li><a href="global.html#vectorizeTextAsConcept">vectorizeTextAsConcept</a></li><li><a href="global.html#weighRelevanceConceptVector">weighRelevanceConceptVector</a></li><li><a href="global.html#weighRelevanceConceptVectorAPI">weighRelevanceConceptVectorAPI</a></li><li><a href="global.html#weighRelevanceTermFrequency">weighRelevanceTermFrequency</a></li></ul></div><div class="category"><h2>Search</h2><h3>Global</h3><ul><li><a href="global.html#searchSTREAM">searchSTREAM</a></li><li><a href="global.html#searchWeb">searchWeb</a></li><li><a href="global.html#searchWikipedia">searchWikipedia</a></li></ul></div><div class="category"><h2>Tokenize</h2><h3>Global</h3><ul><li><a href="global.html#convertWordToRootStem">convertWordToRootStem</a></li><li><a href="global.html#isWordCommonIgnored">isWordCommonIgnored</a></li><li><a href="global.html#splitSentences">splitSentences</a></li><li><a href="global.html#splitTextSemanticChars">splitTextSemanticChars</a></li><li><a href="global.html#suggestNextWordCompletions">suggestNextWordCompletions</a></li><li><a href="global.html#tokenizeTopics">tokenizeTopics</a></li></ul></div><div class="category"><h2>Topic Model</h2><h3>Global</h3><ul><li><a href="global.html#compileTopicModel">compileTopicModel</a></li><li><a href="global.html#compressB64Zip">compressB64Zip</a></li><li><a href="global.html#importCommonQueries">importCommonQueries</a></li><li><a href="global.html#importDictionary">importDictionary</a></li><li><a href="global.html#importHumanNames">importHumanNames</a></li><li><a href="global.html#importMisspelledTypos">importMisspelledTypos</a></li><li><a href="global.html#importTermFrequency">importTermFrequency</a></li><li><a href="global.html#importWikiPageTitles">importWikiPageTitles</a></li><li><a href="global.html#weightWikiWordSpecificity">weightWikiWordSpecificity</a></li></ul></div><div class="category"><h2>Topics</h2><h3>Global</h3><ul><li><a href="global.html#extractSEEKTOPIC">extractSEEKTOPIC</a></li><li><a href="global.html#rankSentencesCentralToKeyphrase">rankSentencesCentralToKeyphrase</a></li><li><a href="global.html#weighTopicDirichletDistribution">weighTopicDirichletDistribution</a></li></ul></div>
                
            </nav>
        </div>
        <div class="core" id="main-content-wrapper">
            <div class="content">
                <header class="page-title">
                    <p>Source</p>
                    <h1>dataset-import/compile-topic-model.js</h1>
                </header>
                



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>import fs from "fs";
import wikiWordFrequency from "../../data/wiki-word-freq-325k.json";

/**
 * Compile a topic phrases model from a dictionary and Wikipedia page titles. &lt;br />
 * Search and outline a research base using Wikipedia's 100k popular pages as the core topic 
 * phrases graph for LLM Research Agents. Most of the documents online (and by extension thinking 
 * in the collective conciousness) can revolve around core topic phrases linked as a graph.  
 * If all the available docs are nodes, the links in the graph can be extracted Wiki page entities 
 * and mappings of dictionary phrases to their wiki page. These can serve as topic labels, keywords, 
 * and suggestions for LLM followup questions. Documents can be linked in a graph with: &lt;br />
 * 1. wiki page entity recognition &lt;br /> 2. frequent keyphrases &lt;br /> 3. html links &lt;br /> 
 * 4. research paper references &lt;br /> 5. keyphrases to query in global web search &lt;br /> 6. site-specific recommendations. &lt;br />
 * These can lay the foundation for LLM Research Agents to fully grok, summarize, and outline a research base.   &lt;br />&lt;br />
 * 240K total words &amp; phrases, first 117K first-word or single words to check every token against. 100K Wikipedia Page Titles and links - Wikipedia most popular pages titles. Also includes domain specificity score and what letters should be capital.&lt;br />
 * 84K  words and 67K phrases in dictionary lexicon  OpenEnglishWordNet, a better updated version of Wordnet - multiple definitions per term, 120k definitions, 45 concept categories&lt;br />
 * JSON Prefix Trie  - arranged by sorting words and phrases for lookup by first word to tokenize by word, then find if it starts a phrase based on entries, for Phrase Extraction from a text. &lt;br /> 
 * There is &lt;a href="https://johnresig.com/blog/javascript-trie-performance-analysis/">"unanimous consensus"&lt;/a> that Prefix Trie &lt;a href="https://github.com/daviddwlee84/LeetCode/blob/master/Notes/DataStructure/Trie_PrefixTree.md">O(1) lookups&lt;/a> (instead of having to loop through the index for each lookup) makes it the best data type for this task.
 * @param {object} options 
 * @param {number} options.addJSONLineBreaks - include line breaks in JSON output for debugging
 * @param {number} options.maxSynonymsPerTerm - max synonyms per term
 * @param {boolean} options.outputJSExport - filetype js instead of json with "export"
 * @param {boolean} options.addWikiPageTitles - true to add wiki page titles, false for dictionary only
 * @param {boolean} options.sortInFirstTwoLettersTrie - sort the first words by first two letters Trie, needd for autocomplete after 2 letters typed
 * @param {number} options.minTermCharCount - min length of term to include
 * @returns {Promise&lt;void>} 
 * @category Topic Model
 */
export async function compileTopicModel(options = {}) {
  const {
    minTermCharCount = 3,
    maxSynonymsPerTerm = 0,
    outputJSExport = false,
    addWikiPageTitles = true,
    sortInFirstTwoLettersTrie = true,
    addJSONLineBreaks = 0,
  } = options;

  //array key: var [nextWords, wikiTitle, category,
  // uniqueness, capsIndexes] = dict[key.slice(0,2)][key];

  const pos_categories = ["n", "v", "r", "a", "s"]; //a and s is for adjectives

  var dict = JSON.parse(fs.readFileSync("./data/dictionary-152k.json", "utf8"));

  var wikiTopPages = JSON.parse(
    fs.readFileSync("./data/wiki-pages-200k.json", "utf8")
  );

  var wordsPhrasesTree = {};

  //  TOP 100K WIKI PAGE TITLE to the tree with the wikipage
  let maxWikiPages = 100000;
  for (var pageTitle of wikiTopPages) {
    //if has parenthesis, skip
    if (pageTitle.includes("(") || pageTitle.includes(")")) continue;

    // remove everything in (parentesis) and [brackets] from the title with regex
    var wpt_words = pageTitle
      .replace(/ *\([^)]*\)/g, "")
      .replace(/ *\[[^)]*\]/g, "")

      .replace(/[ ]+/g, " ")
      .replace(/^List_of_/, "")
      // remove everything after a comma
      // .split(",")[0]
      .replace(/[^a-zA-Z_0-9\-]/g, "")
      .toLowerCase()
      .split("_");

    var wpt_firstWord = wpt_words[0];
    var wpt_phraseSize = wpt_words.length;
    var wpt_nextWords = wpt_words.slice(1)?.join(" ");

    if (wpt_words.join().length &lt; minTermCharCount) continue;

    var wikiObj = addWikiPageTitles
      ? { w: pageTitle, cat: 50 }
      : { w: 1, cat: 50 };
    wikiObj.n = wpt_phraseSize > 1 ? wpt_nextWords : "";

    if (!wordsPhrasesTree[wpt_firstWord]) wordsPhrasesTree[wpt_firstWord] = [];

    wordsPhrasesTree[wpt_firstWord].push(wikiObj);
    maxWikiPages--;
    if (maxWikiPages &lt;= 0) break;
  }

  function totalTreeMap(dict) {
    return [
      Object.keys(dict).length,
      Object.keys(dict).reduce(
        (total, key) => total + Object.keys(dict[key]).length,
        0
      ),
      // get the total number of W: 1
      Object.keys(dict).reduce(
        (total, key) => total + dict[key].filter((x) => x.w).length,
        0
      ),
    ];
  }

  console.log("wikiTopPages", totalTreeMap(wordsPhrasesTree));

  // Add dictionary words &amp; phrases to tree

  for (var key of Object.keys(dict)) {
    var words = key.split(" ");
    var firstWord = words[0];
    var phraseSize = words.length;

    var { syns, cat, pos, caps } = dict[key];

    pos = pos_categories.indexOf(pos);
    if (caps) {
      //compare caps to key and see which letters have capitaication, return their idnexes
      var capsIndexes = [];
      for (var i = 0; i &lt; key.length; i++) {
        if (caps[i] === key[i].toUpperCase()) {
          capsIndexes.push(i);
        }
      }
      caps = capsIndexes; //.join(",");
    }

    syns = syns?.split(",").slice(0, maxSynonymsPerTerm).join(","); //max

    var phraseObj = { cat, pos };
    if (phraseSize > 1) phraseObj.n = words.slice(1)?.join(" ");
    if (syns?.length) phraseObj.s = syns;
    if (caps) phraseObj.caps = caps;

    if (!wordsPhrasesTree[firstWord] || !wordsPhrasesTree[firstWord].push)
      wordsPhrasesTree[firstWord] = [];

    wordsPhrasesTree[firstWord].push(phraseObj);
  }

  console.log("after dict", totalTreeMap(wordsPhrasesTree));

  // combine the same phrases by comparing size and next words
  for (var key of Object.keys(wordsPhrasesTree)) {
    var phrases = wordsPhrasesTree[key];
    var combinedPhrases = [];
    for (var phrase of phrases) {
      var found = false;
      for (var combinedPhrase of combinedPhrases) {
        if ((combinedPhrase.n || "") == (phrase.n || "")) {
          found = true;
          combinedPhrase.w = combinedPhrase.w || phrase.w;
          phrase.w = combinedPhrase.w || phrase.w;
          break;
        }
      }
      if (!found) {
        combinedPhrases.push(phrase);
      }
    }
    wordsPhrasesTree[key] = combinedPhrases;
  }

  for (var key of Object.keys(wordsPhrasesTree)) {
    wordsPhrasesTree[key] = wordsPhrasesTree[key].sort((a, b) => b.s - a.s);
  }

  console.log("after combo", totalTreeMap(wordsPhrasesTree));

  //calculate term specificity and combine into array

  for (var key of Object.keys(wordsPhrasesTree)) {
    var thisKey = key;

    wordsPhrasesTree[key] = wordsPhrasesTree[key].map((next) => {
      //get whole phrase
      var phrase = thisKey + " " + (next.n || "");
      // add uniqueness to the phrase
      next.u = weightWikiWordSpecificity(phrase);
      // next.w,  , next.caps
      var nextArray = [next.n, next.cat, next.u, next.s].map((x) => x || 0);
      return nextArray;
    });
  }

  // prefix tree by the first two letters
  if (sortInFirstTwoLettersTrie) {
    var firstTwoLettersTree = {};
    for (var key of Object.keys(wordsPhrasesTree)) {
      var firstTwoLetters = key.substring(0, 2);
      if (firstTwoLetters in firstTwoLettersTree) {
        firstTwoLettersTree[firstTwoLetters][key] = wordsPhrasesTree[key];
      } else {
        firstTwoLettersTree[firstTwoLetters] = {};
        firstTwoLettersTree[firstTwoLetters][key] = wordsPhrasesTree[key];
      }
    }
  } else {
    var firstTwoLettersTree = wordsPhrasesTree;
  }

  //sort alphabetically by the first two letters
  firstTwoLettersTree = Object.keys(firstTwoLettersTree)
    .sort()
    .reduce((acc, key) => {
      acc[key] = firstTwoLettersTree[key];
      return acc;
    }, {});

  if (outputJSExport)
    fs.writeFileSync(
      "./data/wiki-phrases-model-240k.js",
      "export default " +
        (addJSONLineBreaks
          ? JSON.stringify(firstTwoLettersTree, null, 2)
          : JSON.stringify(firstTwoLettersTree)),
      "utf8"
    );
  else
    fs.writeFileSync(
      "./data/wiki-phrases-model-240k.json",
      addJSONLineBreaks
        ? JSON.stringify(firstTwoLettersTree, null, 2)
        : JSON.stringify(firstTwoLettersTree),
      "utf8"
    );
}

/**
 * Find domain-specific unique words for a single doc with BM25 formula
 * by using Wikipedia term frequencies as the common words corpus.
 * All words in English Wikipedia are sorted by number of pages they are in for 
 * 325K words with frequencies of at least 32 wikipages, between 3 to 23 characters 
 * of Latin alphanumerics like az09, punctuation like .-, and diacritics like éï, 
 * but filtering out numbers and foreign language. &lt;br />
 * &lt;b>Total Terms (frequency>=32)&lt;/b>: 324896 &lt;br />
 * &lt;b>Filesize (JSON, frequency>=32)&lt;/b>: 4MB  &lt;br />
 * &lt;b>Total Articles (Wiki-en-2020)&lt;/b>: 5,989,879 &lt;br /> &lt;br />
 * 
 *  Galkin, M., Malykh, V. (2020). Wikipedia TF-IDF Dataset Release (v1.0). 
 * Zenodo. https://doi.org/10.5281/zenodo.3631674 https://github.com/SmartDataAnalytics/Wikipedia_TF_IDF_Dataset

 * @param {string} query phrase to search wiki-idf for each word
 * @returns {number} score for term specificity 0-12~
 * @category Topic Model
 */
export function weightWikiWordSpecificity(query) {
  const totalWikiPages = 6000000;
  const queryTerms = query.toLowerCase().split(/\W+/);

  let phraseScoreList = queryTerms
    .map((term) => {
      //skip terms that are too short
      if (term.length &lt; 3) return null;

      //calculate IDF from Wikipedia term frequency
      const wikiPagesWithTerm = wikiWordFrequency[term]; //|| 10;

      if (!wikiPagesWithTerm) return null;

      return Math.log(
        (totalWikiPages - wikiPagesWithTerm) / wikiPagesWithTerm + 1
      );
    })
    .filter(Boolean);

  var phraseScore =
    Math.floor(
      phraseScoreList.reduce((a, b) => a + b, 0) / phraseScoreList.length
    ) || 5;
  return phraseScore;
}

await compileTopicModel();
</code></pre>
        </article>
    </section>




            </div>
            
            <footer class="footer">
                <div class="content has-text-centered">
                    <p>Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 4.0.3</a></p>
                    <p class="sidebar-created-by">
                        <a href="https://github.com/SoftwareBrothers/better-docs" target="_blank">BetterDocs theme</a> provided with <i class="fas fa-heart"></i> by
                        <a href="http://softwarebrothers.co" target="_blank">SoftwareBrothers - JavaScript Development Agency</a>
                    </p>
                </div>
            </footer>
            
        </div>
        <div id="side-nav" class="side-nav">
        </div>
    </div>
<script src="scripts/app.min.js"></script>
<script>PR.prettyPrint();</script>
<script src="scripts/linenumber.js"> </script>

<script src="scripts/search.js"> </script>


</body>
</html>
