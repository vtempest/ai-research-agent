"use strict";(self.webpackChunkdocusaurus_openapi_typedoc=self.webpackChunkdocusaurus_openapi_typedoc||[]).push([["4193"],{97725:function(e,n,s){s.r(n),s.d(n,{frontMatter:()=>o,default:()=>h,contentTitle:()=>a,assets:()=>l,toc:()=>d,metadata:()=>r});var r=JSON.parse('{"id":"functions/agents/reply-language","title":"reply-language","description":"Documentation / agents/reply-language","source":"@site/docs/functions/agents/reply-language.md","sourceDirName":"functions/agents","slug":"/functions/agents/reply-language","permalink":"/docs/functions/agents/reply-language","draft":false,"unlisted":false,"editUrl":"https://github.com/vtempest/ai-research-agent/blob/main/docs/functions/agents/reply-language.md","tags":[],"version":"current","frontMatter":{},"sidebar":"default","previous":{"title":"language-model-names","permalink":"/docs/functions/agents/language-model-names"},"next":{"title":"tool","permalink":"/docs/functions/agents/tool"}}'),t=s(74132),i=s(50065);let o={},a=void 0,l={},d=[{value:"Generate",id:"generate",level:2},{value:"generateLanguageResponse()",id:"generatelanguageresponse",level:3},{value:"Generate Language Response",id:"generate-language-response",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Returns",id:"returns",level:4},{value:"See",id:"see",level:4},{value:"Author",id:"author",level:4},{value:"Example",id:"example",level:4}];function c(e){let n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"/docs/functions/modules",children:"Documentation"})," / agents/reply-language"]}),"\n",(0,t.jsx)(n.h2,{id:"generate",children:"Generate"}),"\n",(0,t.jsx)(n.h3,{id:"generatelanguageresponse",children:"generateLanguageResponse()"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:"function generateLanguageResponse(options: object): Promise<{\n  content: string;\n  data: any;\n  error: string;\n}>;\n"})}),"\n",(0,t.jsx)(n.p,{children:"Defined in: agents/reply-language.js:72"}),"\n",(0,t.jsx)("img",{src:"https://i.imgur.com/bailW5n.gif"}),"\n",(0,t.jsx)("img",{src:"https://i.imgur.com/uW6E9VJ.gif"}),"\n",(0,t.jsx)(n.h3,{id:"generate-language-response",children:"Generate Language Response"}),"\n",(0,t.jsx)(n.p,{children:"Generates language response to language prompt with agent templates."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Requires"}),": LLM provider, API Key, and either prompt or context and agent."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Providers"}),": groq, togetherai, openai, anthropic, xai, google, perplexity"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Agent Templates"}),": summarize-bullets(article), summarize(article),\nsuggest-followups(chat_history, article), answer-cite-sources(context, chat_history, query),\nquery-resolution(chat_history, query), knowledge-graph-nodes(query, article),\nsummary-longtext(summaries)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"How it Works"}),": Language models are trained on vast amounts of text to predict\nthe most likely next word or sequence of words given a prompt. They represent words and\ntheir contexts as high-dimensional vectors, allowing them to capture complex relationships\nand nuances in language. Using neural network architectures like transformers, these models\nanalyze input text, apply attention mechanisms to understand context, and generate human-like\nresponses based on learned patterns."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsxs)("table",{children:[(0,t.jsx)("thead",{children:(0,t.jsxs)("tr",{children:[(0,t.jsx)("th",{children:"Parameter"}),(0,t.jsx)("th",{children:"Type"}),(0,t.jsx)("th",{children:"Description"})]})}),(0,t.jsxs)("tbody",{children:[(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options"})})}),(0,t.jsx)("td",{children:(0,t.jsxs)(n.p,{children:["{ ",(0,t.jsx)(n.code,{children:"agent?"}),": ",(0,t.jsx)(n.code,{children:"string"}),"; ",(0,t.jsx)(n.code,{children:"apiKey"}),": ",(0,t.jsx)(n.code,{children:"string"}),"; ",(0,t.jsx)(n.code,{children:"model?"}),": ",(0,t.jsx)(n.code,{children:"string"}),"; ",(0,t.jsx)(n.code,{children:"prompt"}),": ",(0,t.jsx)(n.code,{children:"string"})," | ",(0,t.jsx)(n.code,{children:"any"}),"[]; ",(0,t.jsx)(n.code,{children:"provider"}),": ",(0,t.jsx)(n.code,{children:"string"}),"; ",(0,t.jsx)(n.code,{children:"temperature?"}),": ",(0,t.jsx)(n.code,{children:"number"}),"; }"]})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"parameters"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.agent?"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"string"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"Agent prompt to use with custom variables passed, instead of prompt"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.apiKey"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"string"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"API key for the specified provider"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.model?"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"string"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"Optional model name. If not provided, uses default"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.prompt"})})}),(0,t.jsx)("td",{children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"string"})," | ",(0,t.jsx)(n.code,{children:"any"}),"[]"]})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"User's input query text string or LangChain messages array"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.provider"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"string"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"LLM provider: groq, openai, anthropic, together, xai, google"})})]}),(0,t.jsxs)("tr",{children:[(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"options.temperature?"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"number"})})}),(0,t.jsx)("td",{children:(0,t.jsx)(n.p,{children:"Temperature is a way to control the overall confidence of the model's scores\n(the logits). What this means is that, if you use a lower value than 1.0, the relative\ndistance between the tokens will become larger (more deterministic), and if you use a larger\nvalue than 1.0, the relative distance between the tokens becomes smaller (less deterministic)."})})]})]})]}),"\n",(0,t.jsx)(n.h4,{id:"returns",children:"Returns"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Promise"}),"<{\n",(0,t.jsx)(n.code,{children:"content"}),": ",(0,t.jsx)(n.code,{children:"string"}),";\n",(0,t.jsx)(n.code,{children:"data"}),": ",(0,t.jsx)(n.code,{children:"any"}),";\n",(0,t.jsx)(n.code,{children:"error"}),": ",(0,t.jsx)(n.code,{children:"string"}),";\n}>"]}),"\n",(0,t.jsx)(n.p,{children:'Language response with human-like understanding of the question and context.\n"content" is HTML (or markdown if requested)\n"data" is a JSON object from response extracted by some agents\n"error" is an error message if one occurs'}),"\n",(0,t.jsx)(n.h4,{id:"see",children:"See"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://console.groq.com/docs/overview",children:"Groq Docs"})," ",(0,t.jsx)(n.a,{href:"https://console.groq.com/keys",children:"Groq Keys"}),":\nLlama, Mixtral 8x7B, Gemma2 9B"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://platform.openai.com/docs/overview",children:"OpenAI Docs"})," ",(0,t.jsx)(n.a,{href:"https://platform.openai.com/api-keys",children:"OpenAI Keys"}),":\nGPT-3.5 Turbo, GPT-4, GPT-4 Turbo, GPT-4 Omni, GPT-4 Omni Mini"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://docs.anthropic.com/en/docs/welcome",children:"Anthropic Docs"})," ",(0,t.jsx)(n.a,{href:"https://console.anthropic.com/settings/keys",children:"Anthropic Keys"}),":\nClaude 3.5 Sonnet, Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://docs.together.ai/docs/quickstart",children:"TogetherAI Docs"})," ",(0,t.jsx)(n.a,{href:"https://api.together.xyz/settings/api-keys",children:"TogetherAI Keys"}),":\nLlama, Mistral, Mixtral, Qwen, Gemma, WizardLM, DBRX, DeepSeek, Hermes, SOLAR, StripedHyena."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://docs.x.ai/docs#models",children:"XAI Docs"})," ",(0,t.jsx)(n.a,{href:"https://console.x.ai/",children:"XAI Keys"}),": Grok, Grok Vision"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",children:"Google Vertex Docs"}),"\n",(0,t.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview#api-keys",children:"Google Vertex Keys"}),": Gemini"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"https://docs.perplexity.ai/models/model-cards",children:"Perplexity Docs"}),"\n",(0,t.jsx)(n.a,{href:"https://www.perplexity.ai/settings/keys",children:"Perplexity Keys"}),": Sonar, Sonar Deep Research"]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"author",children:"Author"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE",children:"Language Model Researchers"})}),"\n",(0,t.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-ts",children:'const response = await generateLanguageResponse({\n  prompt: "Explain neural networks",\n  provider: "groq",\n  apiKey: "your-api-key"\n})\n'})})]})}function h(e={}){let{wrapper:n}={...(0,i.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},50065:function(e,n,s){s.d(n,{Z:()=>a,a:()=>o});var r=s(39546);let t={},i=r.createContext(t);function o(e){let n=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);