---
id: generate-language-model-reply-using-agent-prompts
title: "Generate language model reply using agent prompts"
description: "Generates a language model reply using agent prompts."
sidebar_label: "Generate language model reply using agent prompts"
hide_title: true
hide_table_of_contents: true
api: eJztVt9v4zYM/lcIvezFdtq73Q7IWzcctg7t2jW9h6E5DIrN2LrIkivJSXNB/veRsvOjSdAWuL1tRtFIFEVR5MePWokgSy+GD2KEbq5y9OJLIgr0uVNNUNaIofgVDToZ0IMELU3ZyhKhtgVqcNjoJbRemRJIagI0ztZN8NnYjM3V1TXP56pABymUzj4mYBs0UiUgTaicbVSeQLAlhgpdAk+8UlpbamQDAOcZ+LaupVPfMJ20WmPwQ17gLwXpgspZF+DdnuZpjfesUZboQzq1WttF2+zbyisZ/q6UD9YtT+7/MSOn/QLdq5seW+ymH7JunDr0Vrcc0Ldv/imDmbELjUWJaelkU6WGor7v81b3yNmPm3AsU21NGfApnI5KJ/CYs3N+bEQiHJJdH362xVIMV3GqHBZiGFyLicitCZRqXpJNo1Uueevgq2e0rITPK6wlj8KyQcKPnXwl673dztCD2OCC4UbjBskjAh/t6hC0t98HR/gSh7AcLX3AugccTK0DwtABQMU6ERGXr5u7iPA1skYOxyHmkp0oOUZRAmPTQSM5yndyOom85TBBFPx1H96nN3j8++jmD7iJwYVRVAE7hTk5KSeaqnWhQgW0QzZYwJg/QaUGyngKNv3QuA+eVjOE1T4ch2MxFmt2Z5uok/5MZavJVcG1feTgd9U/nz3D5eth+Mu2Di5uL4G0tzC4uNyezIY6MLx4A61lLdP32bv0/HySzpUn62njcK5wwSaqUL9soSuO575dTiGKe6Ik72pJoffw2/31VQa0PJXa0/q1dLPCLkzGRxGsG2bc1uHeiaatJ3SbwyPud8rA0HFW+xgCJ01ha4PeMyxYEqPwg6fIYKG6eieevoBKlRR9Qo5uSQkJyTt1QpHWMOEZH+CQin2OlL0CNJsuMKCrlSHYUCrHZlEpjdwo7OJtJp8ZyCL/bEN6ln1cx4+5wzfkb0cR787O+Od0myq6YIvvIKrnhNSZexWHh+dvPP9wylnuthQfdI4AS3+18rGJ9gXZSEdEFGK6/6VbxKNev8Wn6FFNqSXe7O/ABUQFaom4RWN9tC1DRbNBJFdPAh8vxC+JlWgdVQoVTKD+Ohg8LmYepcurLLf1QDZqcHTorbNFGwEJfWA+312JNbUGvuXdrh19epJ1o3G/Tewu0hP9TrBl0p1ox2Ybyoocs1PomeJlOtiwQVfyz8qVIZsIZab2VNI5DAmQT07mIYE5JcpyT4n1ZNugleHiCcyLMJEeOxKnIr2EO+zCCLFTdZXCIe9sn2dn2RlJggocH/HnYjbq1W8vWU5F5m+m/SuvT89RdjSWUg+iLmfpiVpTGS/yUkoVxdnvZHFP5ucxJTrcdxmIhhhJDKBaRuhys90rnDc/Lg/xs9rVyP+P1f/aY7WnM94zaLRU8Q0V4brqWepB9CxFfFIxfZFkteLq+uz0es3i6BrJabh5P/GM2z7KSBdEax1T/NJBLb3nc1mdOhyJj6h5nWx2XOQ5NuFF3S97DHt7M7on5Un/+mbsktRJph3+PxQ0sBH6XXti2UpswE7rnU3+/gGZb8KY
sidebar_class_name: "post api-method"
info_path: api-routes/qwksearch-api
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Generate language model reply using agent prompts"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/agents"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Generates a language model reply using agent prompts.

LLM provider - groq, openai, anthropic, together, xai, google

  1. summarize-bullets:
      - article
  2. summarize:
      - article
  3. suggest-followups:
      - chat_history
      - article
  4. answer:
      - chat_history
      - query
  5. query-resolution:
      - chat_history
      - query
  6. knowledge-graph-nodes:
      - query
      - article
  7. summary-longtext:
      - article
      - sections


<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={undefined}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"required":true,"content":{"application/json":{"schema":{"type":"object","required":["provider"],"properties":{"prompt":{"type":"string","description":"System prompt for the language model"},"agent":{"type":"string","description":"Agent name - summarize-bullets, summarize, suggest-followups, \nanswer, query-resolution, knowledge-graph-nodes, \nsummary-longtext\n"},"context":{"type":"string","description":"JSON Object String of variables with escaped \\\\\" to insert into prompt like {chat_history:\"\"}"},"provider":{"type":"string","default":"groq","description":"LLM provider - groq, openai, anthropic, together, xai, google"},"key":{"type":"string","description":"Your API key for the AI provider"},"model":{"type":"string","default":"llama-3.2-11b-vision-preview"},"html":{"type":"string","default":true,"description":"If true, reply format is HTML. If false, Markdown."},"temperature":{"type":"number","description":"Temperature controls the randomness of the model's predictions.\nA higher value means the model will be more creative and less deterministic,\nwhile a lower value means the model will be more deterministic.\n","default":0.7}}}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"Generated reply","content":{"application/json":{"schema":{"type":"object","properties":{"reply":{"type":"string","description":"Generated reply"}}}}}},"500":{"description":"Server error or missing prompt parameter","content":{"application/json":{"schema":{"type":"object","properties":{"error":{"type":"string","description":"Error message"}}}}}}}}
>
  
</StatusCodes>

