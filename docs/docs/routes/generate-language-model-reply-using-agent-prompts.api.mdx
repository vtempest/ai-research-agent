---
id: generate-language-model-reply-using-agent-prompts
title: "Generate language model reply using agent prompts"
description: "Generates a language model reply using agent prompts."
sidebar_label: "Generate language model reply using agent prompts"
hide_title: true
hide_table_of_contents: true
api: eJztVk1v4zYQ/SuDufRCyUm22wV0S4tFmyJp0nV6KOKgoKWxxDVFMiRlxzX834uh5NiJjSTA9tbqkFij+eLMmzdcY5R1wOIOx+QXqqSA9wIrCqVXLiprsMCfyZCXkQJI0NLUnawJWluRBk9Or6ALytQgazIRnLetiyGfmIm5vLzi94WqyEMGtbcPAqwjI5UAaWLjrVOlgGhrig15AY/8pba21sQOAE5zCF3bSq/+pmzaaU0xFPyBnwykj6pkXYCzPc3jGh9Yo64pxGxmtbbLzu37KhsZ/2pUiNavjtp/n4M0YUn+TaOHjvrXj3n/O/MUrO64oO83/iGHubFLTVVNWe2lazJjK9rP+Un3INlP23KsMm1NHekxHq9KLwhUcnJhYlCgp4eOQvzRViss1ulVeaqwiL4jgaU1kUzkT9I5rUrJpqOvgdGyxlA21Er+FVeOsEA7/UplHPz2ju5wiwuGm/PWkY+KAlv1CNqzD9ErU+NLWI5XIVI7AA5m1kNs6AVAcSMw4fJtd+cJvka2xOV4iTmxE4lDFAmYmB4a4qDf4ngT2eRlgyaG803lfXxHxr+Or3+D61RcGCcVsDNYSK/kVFOApYoNUCilowom/CBEC8oE8hGUiXZbPK3mBOt9OBYTnOCG03lq1NF8ZrLTEQvk2T5I8Jvmn2PPafV2Gf60nYfzmwuY0+oJBucXT5HZUQ+GV0+gtWxl9iE/y05Pp9lCBWVN5jwtFC3ZRRPb1z30w/E8t4sZJPFAlDPrWxlBBfjl9uoyh4sZzKQOJOBK+nlllybnUJFax4zbedqLaLp2Sv7g+Lc7ZWDoeKtDKoGXprKtoRAYFixJVfgugPNUqX7e84k5h0bVDXlYSN0RtCRN2KnDUmkNU37jAJ5kVAsCaSrQ7LqiSL5VRoWoSjExy0Zp4kVhl+9z+cxBnvjnqaQn+adNepg7grMm9BRxdnLC/46vqaovNn4DUT0npN7dmzh8GX+b+cdjyfK2JQ/kvfVgPbQqpCU6DKSTXrZcmH/vFCnU26f4nDJqKQRZ03AGHiCKja2wQGdD8i1jgwWOErkGFBjSgfgmscbOayywidGFYjR6WM4DSV82eWnbkXTqIOaNt1WX8Iibe4F8si+7FfT5UbZO0/5q2CU/kPtO8MSeO9GOwbY0lXhlpzCww+sUsGWAfsyfjSjDVKAyM3us0Xx0AfQYvSyjgAWV0fIeSTNku6iV4YGJzIUwlYF64p6Y8wv4Qn3pIG2nfjq4zL3v0/wkP0GBUUWuD/6+nI8H9ZsLlpNvw/VsuNkNLTnoiKZa6lHSHaHAx0zbOh3ktTaq0pqwkyWbPCxSS3S87TuQHDF6GDStTHDlBbs3LO++UL4EzXo3F/9fUP9rF9SBwthm5LRU6d6U4LoemOkOB2a6F9gwZRV3uF7zdP3h9WbD4pQaFnf3Ard3Jn7jVU8y0cXdemCKn3qoZbccl9V1x/EP6HgjthbnZUkuvqp7v8eqN9fjWxQ4HW7cjF0s0EumHf5bIAq0Cfr9SmLZGrdgxwJ7n/z8A4w3vr8=
sidebar_class_name: "post api-method"
info_path: routes/qwksearch-api
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Generate language model reply using agent prompts"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/agents"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Generates a language model reply using agent prompts.

LLM provider - groq, openai, anthropic, together, xai, google

  1. summarize-bullets:
      - article
  2. summarize:
      - article
  3. suggest-followups:
      - chat_history
      - article
  4. answer:
      - chat_history
      - query
  5. query-resolution:
      - chat_history
      - query
  6. knowledge-graph-nodes:
      - query
      - article
  7. summary-longtext:
      - article
      - sections


<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={undefined}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"required":true,"content":{"application/json":{"schema":{"type":"object","required":["provider"],"properties":{"prompt":{"type":"string","description":"System prompt for the language model"},"agent":{"type":"string","description":"Agent name - summarize-bullets, summarize, suggest-followups, \nanswer, query-resolution, knowledge-graph-nodes, \nsummary-longtext\n"},"context":{"type":"string","description":"JSON Object String of variables with escaped \\\\\" to insert into prompt like {chat_history:\"\"}"},"provider":{"type":"string","default":"groq","description":"LLM provider - groq, openai, anthropic, together, xai, google"},"key":{"type":"string","description":"Your API key for the AI provider"},"model":{"type":"string","default":"llama-3.2-11b-vision-preview"},"html":{"type":"string","default":true,"description":"If true, reply format is HTML. If false, Markdown."},"temperature":{"type":"number","description":"Temperature controls the randomness of the model's predictions.\nA higher value means the model will be more creative and less deterministic,\nwhile a lower value means the model will be more deterministic.\n","default":0.7}}}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"Generated reply","content":{"application/json":{"schema":{"type":"object","properties":{"reply":{"type":"string","description":"Generated reply"}}}}}},"500":{"description":"Server error or missing prompt parameter","content":{"application/json":{"schema":{"type":"object","properties":{"error":{"type":"string","description":"Error message"}}}}}}}}
>
  
</StatusCodes>

