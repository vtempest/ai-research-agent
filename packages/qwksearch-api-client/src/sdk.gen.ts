// This file is auto-generated by @hey-api/openapi-ts

import type { Options as ClientOptions, TDataShape, Client } from '@hey-api/client-fetch';
import type { ExtractContentData, ExtractContentResponses, ExtractContentErrors, WriteLanguageData, WriteLanguageResponses, WriteLanguageErrors, SearchWebData, SearchWebResponses, SearchWebErrors } from './types.gen';
import { client as _heyApiClient } from './client.gen';

export type Options<TData extends TDataShape = TDataShape, ThrowOnError extends boolean = boolean> = ClientOptions<TData, ThrowOnError> & {
    /**
     * You can provide a client instance returned by `createClient()` instead of
     * individual options. This might be also useful if you want to implement a
     * custom client.
     */
    client?: Client;
    /**
     * You can pass arbitrary values through the `meta` object. This can be
     * used to access values that aren't defined as part of the SDK function.
     */
    meta?: Record<string, unknown>;
};

/**
 * ## Extract structured content and cite from any URL
 * ![Extractor](https://i.imgur.com/nNfHmct.png)
 *
 * ### ðŸšœðŸ“œ Tractor the Text Extractor
 * 1. Main Content Detection: Extract the main content from a URL by combining
 * Mozilla Readability and Postlight Mercury algorithms, utilizing over 100
 * custom adapters for major sites for article, author, date HTML classes.
 * 2. Basic HTML Standardization: Transform complex HTML into a simplified
 * reading-mode format of basic HTML, making it ideal for research note archival
 * and focused reading, with headings, images and links.
 * 3. YouTube Transcript Processing: When a YouTube video URL is detected,
 * retrieve the complete video transcript including both manual captions and
 * auto-generated subtitles, maintaining proper timestamp synchronization and
 * speaker identification where available.
 * 4. PDF to HTML: Process PDF documents by extracting
 * formatted text while intelligently handling line breaks, page headers,
 * footnotes. The system analyzes text height statistics to automatically
 * infer heading levels, creating a properly structured document hierarchy
 * based on standard deviation from mean text size.
 * 5. Citation Information Extraction: Identify and extract citation metadata
 * including author names, publication dates, sources, and titles using HTML
 * meta tags and common class name patterns. The system validates author names
 * against a comprehensive database of 90,000 first and last names,
 * distinguishing between personal and organizational authors to properly
 * format citations.
 * 6. Author Name Formatting: Process author names by checking against
 * known name databases, handling affixes and titles correctly, and determining
 * whether to reverse the name order based on whether it's a personal or
 * organizational author, ensuring proper citation formatting.
 *
 */
export const extractContent = <ThrowOnError extends boolean = false>(options: Options<ExtractContentData, ThrowOnError>) => {
    return (options.client ?? _heyApiClient).get<ExtractContentResponses, ExtractContentErrors, ThrowOnError>({
        url: '/extract',
        ...options
    });
};

/**
 * ## Generate language model reply using agent prompts
 *
 * - *Requires*: LLM provider, API Key, and agent name, and context variables.
 * - *Agent Templates*: summarize-bullets(article), summarize(article),
 * suggest-followups(chat_history, article), answer-cite-sources(context, chat_history, query),
 * query-resolution(chat_history, query), knowledge-graph-nodes(query, article),
 * summary-longtext(summaries)
 * - *How it Works*: Language models are machine learning systems trained on vast amounts of text to predict
 * the most likely next word or sequence of words given a prompt. They represent words and
 * their contexts as high-dimensional vectors, allowing them to capture complex relationships
 * and nuances in language. Using neural network architectures like transformers, these models
 * analyze input text, apply attention mechanisms to understand context, and generate human-like
 * responses based on learned patterns.
 *
 * - *Providers*: groq, togetherai, openai, anthropic, xai, google, perplexity
 * - [Groq Docs](https://console.groq.com/docs/overview) [Groq Keys](https://console.groq.com/keys):
 * Llama, Mixtral 8x7B, Gemma2 9B
 * - [OpenAI Docs](https://platform.openai.com/docs/overview) [OpenAI Keys](https://platform.openai.com/api-keys):
 * GPT-3.5 Turbo, GPT-4, GPT-4 Turbo, GPT-4 Omni, GPT-4 Omni Mini
 * - [Anthropic Docs](https://docs.anthropic.com/en/docs/welcome) [Anthropic Keys](https://console.anthropic.com/settings/keys):
 * Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Sonnet, Claude 3 Haiku
 * - [TogetherAI Docs](https://docs.together.ai/docs/quickstart) [TogetherAI Keys](https://api.together.xyz/settings/api-keys):
 * Llama, Mistral, Mixtral, Qwen, Gemma, WizardLM, DBRX, DeepSeek, Hermes, SOLAR, StripedHyena.
 * - [XAI Docs](https://docs.x.ai/docs#models) [XAI Keys](https://console.x.ai/): Grok, Grok Vision
 * - [Google Vertex Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models)
 * [Google Vertex Keys](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview#api-keys): Gemini
 * - [Perplexity Docs](https://docs.perplexity.ai/models/model-cards)
 * [Perplexity Keys](https://www.perplexity.ai/account/api/keys): Sonar, Sonar Deep Research
 *
 * ![Language Model Response](https://i.imgur.com/bailW5n.gif)
 *
 */
export const writeLanguage = <ThrowOnError extends boolean = false>(options: Options<WriteLanguageData, ThrowOnError>) => {
    return (options.client ?? _heyApiClient).post<WriteLanguageResponses, WriteLanguageErrors, ThrowOnError>({
        url: '/agents',
        ...options,
        headers: {
            'Content-Type': 'application/json',
            ...options.headers
        }
    });
};

/**
 * ## Search the web
 * ![AILogo](https://i.imgur.com/yYMTcTX.png)
 *
 * Search the web by sending a query via SearXNG metasearch engine of 100+ sources.
 * You can specify the type of content you wantâ€”such as general web results,
 * news articles, videos, images, science topics, files, or IT-related
 * informationâ€”by choosing the appropriate category.
 * Additional filters let you narrow results by recency (like results
 * from the past day, week, month, or year), language, and page number.
 * The API returns a structured list of results, each including a title, URL, snippet, domain, and other useful details, making it easy to display or analyze the information. This flexible and robust search tool is ideal for apps, research projects, and any situation where up-to-date, diverse web data is needed.
 *
 * [Searxng Overview](https://medium.com/@elmo92/search-in-peace-with-searxng-an-alternative-search-engine-that-keeps-your-searches-private-accd8cddd6fc)
 *
 */
export const searchWeb = <ThrowOnError extends boolean = false>(options: Options<SearchWebData, ThrowOnError>) => {
    return (options.client ?? _heyApiClient).get<SearchWebResponses, SearchWebErrors, ThrowOnError>({
        url: '/search',
        ...options
    });
};