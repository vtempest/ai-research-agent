// This file is auto-generated by @hey-api/openapi-ts

import type { Client, Options as Options2, TDataShape } from './client';
import { client } from './client.gen';
import type { ExtractContentData, ExtractContentErrors, ExtractContentResponses, SearchWebData, SearchWebErrors, SearchWebResponses, WriteLanguageData, WriteLanguageErrors, WriteLanguageResponses } from './types.gen';

export type Options<TData extends TDataShape = TDataShape, ThrowOnError extends boolean = boolean> = Options2<TData, ThrowOnError> & {
    /**
     * You can provide a client instance returned by `createClient()` instead of
     * individual options. This might be also useful if you want to implement a
     * custom client.
     */
    client?: Client;
    /**
     * You can pass arbitrary values through the `meta` object. This can be
     * used to access values that aren't defined as part of the SDK function.
     */
    meta?: Record<string, unknown>;
};

/**
 * ## Extract structured content and cite from any URL
 *
 * ![Extractor](https://i.imgur.com/nNfHmct.png)
 *
 * ### üöúüìú Tractor the Text Extractor
 * 1. Main Content Detection: Extract the main content from a URL by combining
 * Mozilla Readability and Postlight Mercury algorithms, utilizing over 100
 * custom adapters for major sites for article, author, date HTML classes.
 * 2. Basic HTML Standardization: Transform complex HTML into a simplified
 * reading-mode format of basic HTML, making it ideal for research note archival
 * and focused reading, with headings, images and links.
 * 3. YouTube Transcript Processing: When a YouTube video URL is detected,
 * retrieve the complete video transcript including both manual captions and
 * auto-generated subtitles, maintaining proper timestamp synchronization and
 * speaker identification where available.
 * 4. PDF to HTML: Process PDF documents by extracting
 * formatted text while intelligently handling line breaks, page headers,
 * footnotes. The system analyzes text height statistics to automatically
 * infer heading levels, creating a properly structured document hierarchy
 * based on standard deviation from mean text size.
 * 5. Citation Information Extraction: Identify and extract citation metadata
 * including author names, publication dates, sources, and titles using HTML
 * meta tags and common class name patterns. The system validates author names
 * against a comprehensive database of 90,000 first and last names,
 * distinguishing between personal and organizational authors to properly
 * format citations.
 * 6. Author Name Formatting: Process author names by checking against
 * known name databases, handling affixes and titles correctly, and determining
 * whether to reverse the name order based on whether it's a personal or
 * organizational author, ensuring proper citation formatting.
 *
 */
export const extractContent = <ThrowOnError extends boolean = false>(options: Options<ExtractContentData, ThrowOnError>) => {
    return (options.client ?? client).get<ExtractContentResponses, ExtractContentErrors, ThrowOnError>({
        url: '/extract',
        ...options
    });
};

/**
 * ## Generate language model reply using agent prompts
 *
 *
 * - ‚ùì **Inputs**: üëÑ Language Intelligence Provider, üîë API Key,  ü§ñ agent template name, üß† model name and options,
 * and üÜé context variables for that agent
 * - ü§ñ **Agent Instruction Templates**: [LangHub](https://smith.langchain.com/hub) template or custom:
 * question(query, chat_history), summarize-bullets(article), summarize(article),
 * suggest-followups(chat_history, article), answer-cite-sources(context, chat_history, query),
 * query-resolution(chat_history, query), knowledge-graph-nodes(query, article),
 * summary-longtext(summaries)
 * - üß† **How Language Models Work**: Language models learn from billions of text examples to
 * identify statistical patterns and structures across diverse sources, converting words into
 * high-dimensional vectors‚Äînumerical lists that capture meaning and relationships between concepts.
 * These mathematical representations allow models to understand that "king/queen" share properties
 * and "Paris/France" mirrors "Tokyo/Japan" through their transformer architecture, a neural network
 * backbone that processes information through multiple layers of analysis. The attention mechanism
 * enables the system to dynamically focus on relevant parts of input text when generating each word,
 * maintaining context like humans tracking conversation threads, while calculating probability scores
 * across the entire vocabulary for each word position based on processed context. Rather than retrieving
 * stored responses, models create novel text by selecting the most probable words given learned
 * patterns, maintaining coherence across long passages while adapting to specific prompt nuances
 * through deep pattern recognition.
 * **Self-Attention**: Each word creates three representations: Query (what it's looking for), Key (what
 * it offers), and Value (its actual content). For example, in "The cat sat on the mat," the word "cat"
 * has a Query vector that searches for actions, a Key vector that advertises itself as a subject, and
 * a Value vector containing its semantic meaning as an animal. The attention mechanism calculates how
 * much "cat" should focus on other words by comparing its Query with their Keys - finding high
 * similarity with "sat" (the action) - then combines the corresponding Value vectors to create a
 * contextualized representation where "cat" now understands it's the one doing the sitting.
 *
 * - üìö **Learning Resources**:
 * [LLM Training Example](https://github.com/vtempest/ai-research-agent/blob/master/packages/neural-net/src/train/predict-next-word.js),
 * [LangChain ReactAgent Tools](https://medium.com/@terrycho/how-langchain-agent-works-internally-trace-by-using-langsmith-df23766e7fb4),
 * [Hugging Face Tutorials](https://huggingface.co/learn), [OpenAI Cookbook](https://cookbook.openai.com),
 * [Transformer Overview](https://jalammar.github.io/illustrated-transformer/),
 * [Building Transformer Guide](https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch),
 * [PyTorch Overview](https://www.learnpytorch.io/pytorch_cheatsheet/)
 *
 * ### üëÑ  Language Intelligence Providers (LIPs)
 *
 * | üëÑ Provider | ü§ñ Model Families | üìö Docs | üîë Keys | üí∞ Valuation | üí∏ Revenue (2024) | üí≤ Cost (1M Output) |
 * | :-- | :-- | :-- | :-- | :-- | :-- | :-- |
 * | **XAI** | Grok, Grok Vision | [Docs](https://docs.x.ai/docs#models) | [Keys](https://console.x.ai/) | \$80B | \$100M | \$15.00 |
 * | **Groq** | Llama, DeepSeek, Gemini, Mistral | [Docs](https://console.groq.com/docs/overview) | [Keys](https://console.groq.com/keys) | \$2.8B | - | \$0.79 |
 * | **Ollama** | llama, mistral, mixtral, vicuna, gemma, qwen, deepseek, openchat, openhermes, codelama, codegemma, llava, minicpm, wizardcoder, wizardmath, meditrion, falcon | [Docs](https://ollama.com/docs) | [Keys](https://ollama.com/settings/keys) | - | \$3.2M | \$0 |
 * | **OpenAI** | o1, o1-mini, o4, o4-mini, gpt-4, gpt-4-turbo, gpt-4-omni | [Docs](https://platform.openai.com/docs/overview) | [Keys](https://platform.openai.com/api-keys) | \$300B | \$3.7B | \$8.00 |
 * | **Anthropic** | Claude Sonnet, Claude Opus, Claude Haiku | [Docs](https://docs.anthropic.com/en/docs/welcome) | [Keys](https://console.anthropic.com/settings/keys) | \$61.5B | \$1B | \$15.00 |
 * | **TogetherAI** | Llama, Mistral, Mixtral, Qwen, Gemma, WizardLM, DBRX, DeepSeek, Hermes, SOLAR, StripedHyena | [Docs](https://docs.together.ai/docs/quickstart) | [Keys](https://api.together.xyz/settings/api-keys) | \$3.3B | \$50M | \$0.90 |
 * | **Perplexity** | Sonar, Sonar Deep Research | [Docs](https://docs.perplexity.ai/models/model-cards) | [Keys](https://www.perplexity.ai/account/api/keys) | \$18B | \$20M | \$15.00 |
 * | **Cloudflare** | Llama, Gemma, Mistral, Phi, Qwen, DeepSeek, Hermes, SQL Coder, Code Llama | [Docs](https://developers.cloudflare.com/workers-ai/) | [Keys](https://dash.cloudflare.com/profile/api-tokens) | \$62.3B | \$1.67B | \$2.25 |
 * | **Google** | Gemini | [Docs](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models) | [Keys](https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview#api-keys) | - | ~$400M | \$10.00 |
 *
 * ![agent_arch_viz](https://i.imgur.com/bailW5n.gif)
 * ![agent_arch_viz2](https://i.imgur.com/uW6E9VJ.gif)
 *
 */
export const writeLanguage = <ThrowOnError extends boolean = false>(options: Options<WriteLanguageData, ThrowOnError>) => {
    return (options.client ?? client).post<WriteLanguageResponses, WriteLanguageErrors, ThrowOnError>({
        url: '/agents',
        ...options,
        headers: {
            'Content-Type': 'application/json',
            ...options.headers
        }
    });
};

/**
 * ## Search the web
 *
 * ![AILogo](https://i.imgur.com/yYMTcTX.png)
 *
 * Search the web by sending a query via SearXNG metasearch engine of 100+ sources.
 * You can specify the type of content you want‚Äîsuch as general web results,
 * news articles, videos, images, science topics, files, or IT-related
 * information‚Äîby choosing the appropriate category.
 * Additional filters let you narrow results by recency (like results
 * from the past day, week, month, or year), language, and page number.
 * The API returns a structured list of results, each including a title, URL, snippet, domain, and other useful details, making it easy to display or analyze the information. This flexible and robust search tool is ideal for apps, research projects, and any situation where up-to-date, diverse web data is needed.
 * [Searxng Overview](https://medium.com/@elmo92/search-in-peace-with-searxng-an-alternative-search-engine-that-keeps-your-searches-private-accd8cddd6fc)
 *
 * **Web Search Stats**:
 * Google processses 90% of Web Search, 13.6 billion searches every day‚Äîalmost 5 trillion per year.
 * Its search index exceeds 100,000,000 GB and covers 130 trillion pages.
 * Ranking uses over 200 factors, including keyword relevance, backlinks, page speed, and user experience; the top organic result gets about 22% of clicks, and ads allow monetizing keyword traffic.
 *
 */
export const searchWeb = <ThrowOnError extends boolean = false>(options: Options<SearchWebData, ThrowOnError>) => {
    return (options.client ?? client).get<SearchWebResponses, SearchWebErrors, ThrowOnError>({
        url: '/search',
        ...options
    });
};
