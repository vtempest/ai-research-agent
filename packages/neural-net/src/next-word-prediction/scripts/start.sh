
#!/bin/bash

echo "ğŸ§  ====================================================================="
echo "ğŸš€ TRANSFORMER LANGUAGE MODEL TRAINING WITH TINYGRAD"
echo "ğŸ§  ====================================================================="
echo ""
echo "ğŸ“‹ Available commands:"
echo "   ğŸƒ python src/training/train_next_word_prediction.py          - Run basic training demo"
echo "   ğŸ“Š python src/training/train_next_word_prediction.py | tee log.txt - Save training log"
echo "   ğŸ”§ python -c 'from tinygrad.tensor import Tensor; print(Tensor([1,2,3]))' - Test tinygrad"
echo "   ğŸ“ˆ jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root - Start Jupyter"
echo ""
echo "ğŸ’¡ Tips:"
echo "   â€¢ First run: Just execute 'python train_next_word_prediction.py'"
echo "   â€¢ GPU support: Tinygrad will auto-detect and use available GPUs"
echo "   â€¢ Modify hyperparameters in src/training/train_next_word_prediction.py for experiments"
echo "   â€¢ Check /app/logs/ for saved training outputs"
echo ""
echo "ğŸ“š Documentation:"
echo "   â€¢ README.md contains full usage instructions"
echo "   â€¢ Transformer paper: https://arxiv.org/abs/1706.03762"
echo "   â€¢ Tinygrad docs: https://docs.tinygrad.org/"
echo ""

# Check if GPU is available
python -c "
import subprocess
try:
    from tinygrad.runtime.ops_gpu import GPU
    print('ğŸ® GPU acceleration: Available')
except:
    print('ğŸ’» GPU acceleration: Not available (CPU mode)')
"

echo ""
echo "ğŸ¯ Ready to explore transformer architecture!"
echo "ğŸ’¡ Start with: python src/training/train_next_word_prediction.py"
echo ""