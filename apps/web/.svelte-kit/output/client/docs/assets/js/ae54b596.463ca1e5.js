"use strict";(self.webpackChunkqwksearch_api_docs=self.webpackChunkqwksearch_api_docs||[]).push([[5916],{71184:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>c});var s=r(14041);const i={},t=s.createContext(i);function l(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(t.Provider,{value:n},e.children)}},78453:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"functions/agents/generate-language","title":"generate-language","description":"ai-research-agent / agents/generate-language","source":"@site/src/functions/agents/generate-language.md","sourceDirName":"functions/agents","slug":"/functions/agents/generate-language","permalink":"/docs/functions/agents/generate-language","draft":false,"unlisted":false,"editUrl":"https://github.com/vtempest/ai-research-agent/tree/master/apps/docs/src/functions/agents/generate-language.md","tags":[],"version":"current","frontMatter":{},"sidebar":"default","previous":{"title":"api2ai","permalink":"/docs/functions/agents/api2ai"},"next":{"title":"language-model-names","permalink":"/docs/functions/agents/language-model-names"}}');var i=r(31085),t=r(71184);const l={},c=void 0,a={},o=[{value:"Generate",id:"generate",level:2},{value:"generateLanguageResponse()",id:"generatelanguageresponse",level:3},{value:"Generate Language Response",id:"generate-language-response",level:3},{value:"Parameters",id:"parameters",level:4},{value:"Returns",id:"returns",level:4},{value:"See",id:"see",level:4},{value:"\ud83d\udc44 LIPs: Language Intelligence Providers",id:"-lips-language-intelligence-providers",level:3},{value:"Author",id:"author",level:4},{value:"Example",id:"example",level:4}];function d(e){const n={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.a,{href:"/docs/functions/modules",children:"ai-research-agent"})," / agents/generate-language"]}),"\n",(0,i.jsx)(n.h2,{id:"generate",children:"Generate"}),"\n",(0,i.jsx)(n.h3,{id:"generatelanguageresponse",children:"generateLanguageResponse()"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:"function generateLanguageResponse(options: object): Promise<{\n  content: string;\n  error: string;\n  extract: any;\n}>;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Defined in: ",(0,i.jsx)(n.a,{href:"https://github.com/vtempest/ai-research-agent/tree/master/packages/ai-research-agent/src/agents/generate-language.js#L105",children:"src/agents/generate-language.js:105"})]}),"\n",(0,i.jsx)(n.h3,{id:"generate-language-response",children:"Generate Language Response"}),"\n",(0,i.jsx)(n.p,{children:"Writes language response showing human-like understanding of the question and context."}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Requires"}),": LLM provider, API Key, agent name, and context input variables for agent."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Providers"}),": groq, togetherai, openai, anthropic, xai, google, perplexity, ollama, cloudflare"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"Agent Templates"}),": any template from ",(0,i.jsx)(n.a,{href:"https://smith.langchain.com/hub",children:"LangHub"})," or custom:\nsummarize-bullets(article), summarize(article), summary-longtext(summaries),\nsuggest-followups(chat_history, article), answer-cite-sources(context, chat_history, query),\nquery-resolution(chat_history, query), knowledge-graph-nodes(query, article)"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.em,{children:"How it Works"}),": Language models are trained on vast amounts of text to predict\nthe most likely next word or sequence of words given a prompt. They represent words and\ntheir contexts as high-dimensional vectors, allowing them to capture complex relationships\nand nuances in language. Using neural network architectures like transformers, these models\nanalyze input text, apply attention mechanisms to understand context by multiplying scores\nof all other words, using multiple attention head starting points, and generate human-like\nresponses based on learned patterns."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"parameters",children:"Parameters"}),"\n",(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"Parameter"}),(0,i.jsx)("th",{children:"Type"}),(0,i.jsx)("th",{children:"Description"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options"})})}),(0,i.jsx)("td",{children:(0,i.jsxs)(n.p,{children:["{ ",(0,i.jsx)(n.code,{children:"agent?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"apiKey?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"applyContextLimit?"}),": ",(0,i.jsx)(n.code,{children:"boolean"}),"; ",(0,i.jsx)(n.code,{children:"article?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"chat_history?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"html?"}),": ",(0,i.jsx)(n.code,{children:"boolean"}),"; ",(0,i.jsx)(n.code,{children:"LANGCHAIN_API_KEY?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"model?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"provider"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"query?"}),": ",(0,i.jsx)(n.code,{children:"string"}),"; ",(0,i.jsx)(n.code,{children:"temperature?"}),": ",(0,i.jsx)(n.code,{children:"number"}),"; }"]})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Configuration parameters for language model generation"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.agent?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Name of the agent prompt template to use. Can include custom variables"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.apiKey?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsxs)(n.p,{children:['API key for the specified provider. Not required for ollama.\nFor cloudflare, use format: "key',":accountId",'"']})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.applyContextLimit?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"boolean"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Whether to enforce model's context length limits"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.article?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Article text to process (required for some agents)"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.chat_history?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Previous conversation history (required for some agents)"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.html?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"boolean"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Set to true to return response in HTML format, false for markdown"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.LANGCHAIN_API_KEY?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"API key for LangChain tracing functionality"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.model?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"Specific model name to use. If not provided, uses provider's default model"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.provider"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsxs)("td",{children:[(0,i.jsx)(n.p,{children:"Language model provider to use. Supported providers:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"groq, togetherai, openai, anthropic, xai, google, perplexity, ollama, cloudflare"}),"\n"]})]})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.query?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"string"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:"User's input query text (required for some agents)"})})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"options.temperature?"})})}),(0,i.jsx)("td",{children:(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"number"})})}),(0,i.jsxs)("td",{children:[(0,i.jsx)(n.p,{children:"Controls response randomness:"}),(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Values < 1.0: More deterministic, focused responses"}),"\n",(0,i.jsx)(n.li,{children:"Values > 1.0: More creative, varied responses"}),"\n",(0,i.jsx)(n.li,{children:"Default: 1.0 (balanced)"}),"\n"]})]})]})]})]}),"\n",(0,i.jsx)(n.h4,{id:"returns",children:"Returns"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Promise"}),"<{\n",(0,i.jsx)(n.code,{children:"content"}),": ",(0,i.jsx)(n.code,{children:"string"}),";\n",(0,i.jsx)(n.code,{children:"error"}),": ",(0,i.jsx)(n.code,{children:"string"}),";\n",(0,i.jsx)(n.code,{children:"extract"}),": ",(0,i.jsx)(n.code,{children:"any"}),";\n}>"]}),"\n",(0,i.jsx)(n.p,{children:"Response object containing:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"content: Generated response in HTML/markdown format"}),"\n",(0,i.jsx)(n.li,{children:"extract: JSON object with extracted data (for supported agents)"}),"\n",(0,i.jsx)(n.li,{children:"error: Error message if generation fails"}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"see",children:"See"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://medium.com/@terrycho/how-langchain-agent-works-internally-trace-by-using-langsmith-df23766e7fb4",children:"LangChain ReactAgent Tools"}),"\n",(0,i.jsx)(n.a,{href:"https://huggingface.co/learn",children:"Hugging Face Tutorials"}),"\n",(0,i.jsx)(n.a,{href:"https://jalammar.github.io/illustrated-transformer/",children:"Transformer Overview"}),"\n",(0,i.jsx)(n.a,{href:"https://www.datacamp.com/tutorial/building-a-transformer-with-py-torch",children:"Building Transformer Guide"}),"\n",(0,i.jsx)(n.a,{href:"https://www.learnpytorch.io/pytorch_cheatsheet/",children:"PyTorch Overview"}),"\n",(0,i.jsx)(n.a,{href:"https://github.com/vtempest/ai-research-agent/blob/master/packages/neural-net/src/train/predict-next-word.js",children:"LLM Training Example"})]}),"\n"]}),"\n",(0,i.jsx)("img",{src:"https://i.imgur.com/bailW5n.gif"}),"\n",(0,i.jsx)("img",{src:"https://i.imgur.com/uW6E9VJ.gif"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["\n",(0,i.jsx)(n.h3,{id:"-lips-language-intelligence-providers",children:"\ud83d\udc44 LIPs: Language Intelligence Providers"}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"IDs"}),": groq, togetherai, openai, anthropic, xai, google, perplexity, ollama, cloudflare"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"XAI"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://docs.x.ai/docs#models",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://console.x.ai/",children:"Keys"})," \ud83d\udcb0 80B ($ valuation) \ud83d\udcb8 100M ($ 2024 revenue):\nGrok, Grok Vision"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Groq"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://console.groq.com/docs/overview",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://console.groq.com/keys",children:"Keys"})," \ud83d\udcb0 2.8B:\nLlama, DeepSeek, Gemini, Mistral"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Ollama"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://ollama.com/docs",children:"Docs"}),"  \ud83d\udcb8 3.2M: llama, mistral, mixtral, vicuna, gemma, qwen, deepseek, openchat,\nopenhermes, codelama, codegemma, llava, minicpm, wizardcoder, wizardmath, meditrion, falcon"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"OpenAI"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/docs/overview",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://platform.openai.com/api-keys",children:"Keys"})," \ud83d\udcb0 300B \ud83d\udcb8 3.7B:\no1, o1-mini, o4, o4-mini, gpt-4, gpt-4-turbo, gpt-4-omni"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Anthropic"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://docs.anthropic.com/en/docs/welcome",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://console.anthropic.com/settings/keys",children:"Keys"})," \ud83d\udcb0 61.5B \ud83d\udcb8 1B:\nClaude Sonnet, Claude Opus, Claude Haiku"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"TogetherAI"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://docs.together.ai/docs/quickstart",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://api.together.xyz/settings/api-keys",children:"Keys"})," \ud83d\udcb0 3.3B \ud83d\udcb8 50M:\nLlama, Mistral, Mixtral, Qwen, Gemma, WizardLM, DBRX, DeepSeek, Hermes, SOLAR, StripedHyena"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Perplexity"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://docs.perplexity.ai/models/model-cards",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://www.perplexity.ai/account/api/keys",children:"Keys"})," \ud83d\udcb0 18B \ud83d\udcb8 20M :\nSonar, Sonar Deep Research"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Cloudflare"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://developers.cloudflare.com/workers-ai/",children:"Docs"})," \ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://dash.cloudflare.com/profile/api-tokens",children:"Keys"})," \ud83d\udcb0 62.3B \ud83d\udcb8 1.67B:\nLlama, Gemma, Mistral, Phi, Qwen, DeepSeek, Hermes, SQL Coder, Code Llama"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Google Vertex"})," \ud83d\udcda ",(0,i.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models",children:"Docs"}),"\n\ud83d\udd11 ",(0,i.jsx)(n.a,{href:"https://cloud.google.com/vertex-ai/generative-ai/docs/start/express-mode/overview#api-keys",children:"Keys"}),": Gemini"]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"author",children:"Author"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://arc.net/folder/D0472A20-9C20-4D3F-B145-D2865C0A9FEE",children:"Language Model Researchers"})}),"\n",(0,i.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-ts",children:'const response = await generateLanguageResponse({\n  query: "Explain neural networks",\n  agent: "question",\n  provider: "groq",\n  apiKey: "your-api-key"\n})\n'})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}}}]);